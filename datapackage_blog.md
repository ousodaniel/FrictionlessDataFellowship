# Data package is valid!

The last few months have been exciting, to say the least. I dug deep into seeking understand how to minimise friction in data workflows and promote openness and reproducibility. I have been able to Know of various FD softwares for improving data publishing workflows through the [FD Field Guide](http://fellows.frictionlessdata.io/blog/). We've looked at a number of case tudies where FD synergised well for reproducibility, an example is on the [eLife study](https://frictionlessdata.io/articles/elife/). We also looked at contributing and coding [best practices](https://github.com/okfn/coding-standards). More over, I found [Understanding JSON schemas](https://json-schema.org/understanding-json-schema/about.html#about) (by json-schema.org) a great guide in understanding the datapackage schema, which is JSON-based. It all culminated in the creation of a data package, which I now want to share my experience on.

To quality check the integrity of your data package creation, you must validate it before downloading it for sharing, among many things. The best you can get from that process is **"Data package is valid!"**. What about before then? 

## Data package
Simply, I would say, it is data coupled to its associated attributes in a JSON format. To marry the data to its attributes you will require a FD tool. [Here](https://github.com/ousodaniel/FrictionlessDataFellowship/blob/master/datapackage-hrma_validation.json) is the one I created.

## [Data Package Creator (DPC)](http://create.frictionlessdata.io/)
A DPC gives you a data package. The good news is that is takes care of both realms of users; programmers and GUI users. I will describe the latter case. It is a web app with three main componenets: One, the "Metadata" pane on the left. Two, the resource (a data article) pane in the middle and the third is the schema on the right pane (usually hidden, but can be exposed by clicking the tree-dots-in-curly-brackets icon).

## The Data
I used my project data in which I was evaluating the application of a molecular technique, high-resolution menting analysis, in the identification of wildlife species illegally consummed as bushmeat. I had two files containing tabular data: one with sample information on samples analysed and sequences deposited in GenBank and the other on species identification blind validation across three mitichondrial markers. My data package thus had thwo resources. This data was contained in my local repository, but I shipped it into [GitHub](https://github.com/ousodaniel/data) in the `CSV` format for easy accessibility.

## Creating the Data Package
You may follow along with this [data package specifications](https://frictionlessdata.io/specs/data-package/). On the `resource` pane tab, from left to right, I entered a `name` for my resource and the `path`. I pasted the raw GitHub link to my data on the provided `path` field and licked the `load` button to the right. DPC automatically inferred the data structure and prompted me to load the inferred field (columns). I counter checked that the data types for each field was correctly inferred, addedt titles and descriptions. The data format for each field was left as default. From the gear-wheel (`setting`)in the resource tab, I gave each of the two resources titiles, descriptions format and encoding. The reource profile was also automatically inferred. All the field and resource metadat data that I inputed are optional, except we want want to ontentionally reproducible and open. On the other hand, there are compulsary metadata information for the general data package, in the `meatadata` pane. They are `name` and `title`. Be careful to get the `name` data package `metadata` right, it must match the pattern `^([-a-z0-9._/])+$` for the datapackage to be valid.
